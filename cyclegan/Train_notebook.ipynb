{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import datetime\n",
    "import PIL\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "from CycleGAN import CycleGAN\n",
    "from ImageDataset import ImageDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--lambda'], dest='lambda', nargs=None, const=None, default=10, type=<class 'float'>, choices=None, help='weighr for cycle consistency loss', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--epoch', type=int, default=10, help='starting epoch')\n",
    "parser.add_argument('--dataroot', type=str, default='../datasets/monet2photo/', help='root directory of the dataset')\n",
    "parser.add_argument('--lr', type=float, default=0.0002, help='initial learning rate')\n",
    "parser.add_argument('--size', type=int, default=256, help='size of the data crop (squared assumed)')\n",
    "parser.add_argument('--input_nc', type=int, default=3, help='number of channels of input data')\n",
    "parser.add_argument('--output_nc', type=int, default=3, help='number of channels of output data')\n",
    "parser.add_argument('--cuda', action='store_true', help='use GPU computation')\n",
    "parser.add_argument('--n_cpu', type=int, default=8, help='number of cpu threads to use during batch generation')\n",
    "parser.add_argument('--batchSize', type=int, default=1, help='batch size')\n",
    "parser.add_argument('--epochs', type=int, default=200, help='number of epochs')\n",
    "parser.add_argument('--lambda', type=float, default=10, help='weighr for cycle consistency loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('--batchSize', type=int, default=1, help='batch size')\n",
    "#     parser.add_argument('--epochs', type=int, default=200, help='number of epochs')\n",
    "#     parser.add_argument('--lr', type=float, default=0.0002, help='initial learning rate')\n",
    "#     parser.add_argument('--lambda', type=float, default=10, help='weighr for cycle consistency loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class opt():\n",
    "    batchSize = 4\n",
    "    epochs = 100\n",
    "    lr = 0.001\n",
    "    lambd = 10\n",
    "    cuda = True\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp = opt()\n",
    "hp.batchSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "# batch_size = 200\n",
    "num_epochs = opt.epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(num_epochs,acc_list,loss_list):\n",
    "    #usage : plot_graph(num_epochs,acc_list,loss_list)\n",
    "    plt.ioff()\n",
    "    fig = plt.figure()\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.ylabel('Training loss')\n",
    "    plt.plot(np.arange(num_epochs), loss_list, 'k-')\n",
    "    plt.title('Training Loss and Training Accuracy')\n",
    "    plt.xticks(np.arange(num_epochs, dtype=int))\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(np.arange(num_epochs), acc_list, 'b-')\n",
    "    plt.ylabel('Training Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.xticks(np.arange(num_epochs, dtype=int))\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"plot.png\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(image,batch_id,name,directory):\n",
    "    file_name = directory+\"/\"+ str(batch_id) + \"_\"+name + \".png\"\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(image.detach().cpu()[0].permute(1,2,0))\n",
    "    fig.savefig(file_name, bbox_inches='tight')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6287\n",
      "751\n"
     ]
    }
   ],
   "source": [
    "#256 x 256\n",
    "transform_train = [transforms.RandomCrop(256, padding=4),transforms.RandomHorizontalFlip(p=2),\n",
    "                   transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])]\n",
    "transform_test = [transforms.ToTensor()]\n",
    "trainset = ImageDataset('../datasets/monet2photo/', transforms_=transform_train,mode='train')\n",
    "testset = ImageDataset('../datasets/monet2photo/', transforms_=transform_train,mode='test')\n",
    "train_loader = DataLoader(trainset,batch_size=hp.batchSize, shuffle=True)\n",
    "test_loader = DataLoader(testset,batch_size=hp.batchSize, shuffle=True)\n",
    "print(len(trainset))\n",
    "print(len(testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CycleGAN(hp).to(device)\n",
    "directory = 'test_output'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "# scheduler = lr_scheduler.StepLR(optimizer, step_size=scheduler_step_size, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/100\n",
      "TimeStamp:Tue Nov 12 00:20:01 2019,Epoch:1, Training Time: 3.2799153327941895,lossD_A :9.727933502290398e-05,lossD_B:9.19467638595961e-05,loss_G:0.0014197997516021132\n",
      "epoch 2/100\n",
      "TimeStamp:Tue Nov 12 00:20:03 2019,Epoch:2, Training Time: 2.0195977687835693,lossD_A :8.592539961682633e-05,lossD_B:8.751609129831195e-05,loss_G:0.0012736188946291804\n",
      "epoch 3/100\n",
      "TimeStamp:Tue Nov 12 00:20:06 2019,Epoch:3, Training Time: 2.555234670639038,lossD_A :9.271380258724093e-05,lossD_B:8.625534974271432e-05,loss_G:0.001180892577394843\n",
      "epoch 4/100\n",
      "TimeStamp:Tue Nov 12 00:20:08 2019,Epoch:4, Training Time: 2.2275476455688477,lossD_A :8.524882287019864e-05,lossD_B:9.563074127072468e-05,loss_G:0.0011835899204015732\n",
      "epoch 5/100\n",
      "TimeStamp:Tue Nov 12 00:20:10 2019,Epoch:5, Training Time: 2.07548189163208,lossD_A :8.447624713880941e-05,lossD_B:9.358255192637444e-05,loss_G:0.0009709849255159497\n",
      "epoch 6/100\n",
      "TimeStamp:Tue Nov 12 00:20:12 2019,Epoch:6, Training Time: 2.124317169189453,lossD_A :8.891572360880673e-05,lossD_B:8.749777771299705e-05,loss_G:0.0008482628618367016\n",
      "epoch 7/100\n",
      "TimeStamp:Tue Nov 12 00:20:14 2019,Epoch:7, Training Time: 1.9828424453735352,lossD_A :8.760182390687987e-05,lossD_B:8.90676528797485e-05,loss_G:0.0009493748657405376\n",
      "epoch 8/100\n",
      "TimeStamp:Tue Nov 12 00:20:16 2019,Epoch:8, Training Time: 2.0674705505371094,lossD_A :8.430224261246622e-05,lossD_B:9.067299106391147e-05,loss_G:0.0009345814469270408\n",
      "epoch 9/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e186294d9718>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m#show_image(B)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mlossD_A\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlossD_B\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_G\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfake_B\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcyclic_A\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfake_A\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcyclic_B\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mloss_A\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mlossD_A\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mloss_B\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mlossD_B\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\cs547\\ReimplementCycleGAN\\cyclegan\\CycleGAN.py\u001b[0m in \u001b[0;36moptimize_parameters\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_G\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_genA2B\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_genB2A\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_cyclic_A\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_cyclic_B\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#opt.lambd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_G\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_G\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \"\"\"\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "loss_list = []\n",
    "loss_A = 0\n",
    "loss_B = 0\n",
    "loss_model_G = 0\n",
    "for epoch in range(1,num_epochs+1):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    acc = 0.0\n",
    "    print(\"epoch {}/{}\".format(epoch,num_epochs))\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        #print('--------')\n",
    "        #print(data)\n",
    "        A = data['A'].to(device)\n",
    "        B = data['B'].to(device)\n",
    "        #print(B.shape)\n",
    "        #show_image(A)\n",
    "        #show_image(B)\n",
    "        model.load(A, B)\n",
    "        lossD_A,lossD_B,loss_G,fake_B,cyclic_A,fake_A,cyclic_B = model.optimize_parameters()\n",
    "        loss_A+=lossD_A\n",
    "        loss_B+=lossD_B\n",
    "        loss_model_G+=loss_G\n",
    "#         save_image(A,batch_idx,'input_A',directory)\n",
    "#         save_image(B,batch_idx,'input_B',directory)\n",
    "#         save_image(cyclic_A,batch_idx,'cyclic_A',directory)\n",
    "#         save_image(fake_B,batch_idx,'fake_B',directory)\n",
    "#         save_image(fake_A,batch_idx,'fake_A',directory)\n",
    "#         save_image(cyclic_B,batch_idx,'cyclic_B',directory)\n",
    "#         break\n",
    "    loss_A/=len(trainset)\n",
    "    loss_B/=len(trainset)\n",
    "    loss_model_G/=len(trainset)\n",
    "    end_time = time.time()\n",
    "    print('TimeStamp:{},Epoch:{}, Training Time: {},lossD_A :{},lossD_B:{},loss_G:{}'.format(time.ctime(),epoch,end_time-start_time,loss_A,loss_B,loss_model_G))\n",
    "    if epoch%2 == 0:\n",
    "        torch.save(model,'C_GAN.model')\n",
    "#     correct = 0\n",
    "#     with torch.no_grad():\n",
    "#         #model.eval()\n",
    "#         start_time = time.time()\n",
    "#         for batch_idx, (A,B) in enumerate(test_loader):\n",
    "#             A = A.to(device)\n",
    "#             B = B.to(device)\n",
    "#             model.load(A,B)\n",
    "#             #model.optimize_parameters()\n",
    "#             #_,predicted = torch.max(outputs.data,1)\n",
    "#             #correct+=torch.sum(predicted==labels).item()\n",
    "#         end_time = time.time()\n",
    "#         print('Testing Time: ',end_time-start_time ,'s, Testing Accurarcy: ',correct/len(testset))\n",
    "print('-' * 20)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "loss_A = 0\n",
    "loss_B = 0\n",
    "loss_model_G = 0\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(test_loader):\n",
    "        A = data['A'].to(device)\n",
    "        B = data['B'].to(device)\n",
    "        model.load(A,B)\n",
    "        ## fix these\n",
    "        lossD_A,lossD_B,loss_G,fake_B,cyclic_A,fake_A,cyclic_B = model.forward()\n",
    "        loss_B+=lossD_B\n",
    "        loss_model_G+=loss_G\n",
    "        save_image(A,batch_idx,'input_A',directory)\n",
    "        save_image(B,batch_idx,'input_B',directory)\n",
    "        save_image(cyclic_A,batch_idx,'cyclic_A',directory)\n",
    "        save_image(fake_B,batch_idx,'fake_B',directory)\n",
    "        save_image(fake_A,batch_idx,'fake_A',directory)\n",
    "        save_image(cyclic_B,batch_idx,'cyclic_B',directory)\n",
    "loss_A/=len(testset)\n",
    "loss_B/=len(testset)\n",
    "loss_model_G/=len(testset)\n",
    "print('lossD_A :{},lossD_B:{},loss_G:{}'.format(loss_A,loss_B,loss_model_G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(num_epochs,acc_list,loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model,'cycleGAN.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
