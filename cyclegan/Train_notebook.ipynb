{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import datetime\n",
    "import PIL\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from CycleGAN import CycleGAN\n",
    "from ImageDataset import ImageDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--lambda'], dest='lambda', nargs=None, const=None, default=10, type=<class 'float'>, choices=None, help='weighr for cycle consistency loss', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--epoch', type=int, default=0, help='starting epoch')\n",
    "parser.add_argument('--dataroot', type=str, default='../datasets/monet2photo/', help='root directory of the dataset')\n",
    "parser.add_argument('--lr', type=float, default=0.0002, help='initial learning rate')\n",
    "parser.add_argument('--size', type=int, default=256, help='size of the data crop (squared assumed)')\n",
    "parser.add_argument('--input_nc', type=int, default=3, help='number of channels of input data')\n",
    "parser.add_argument('--output_nc', type=int, default=3, help='number of channels of output data')\n",
    "parser.add_argument('--cuda', action='store_true', help='use GPU computation')\n",
    "parser.add_argument('--n_cpu', type=int, default=8, help='number of cpu threads to use during batch generation')\n",
    "parser.add_argument('--batchSize', type=int, default=1, help='batch size')\n",
    "parser.add_argument('--epochs', type=int, default=200, help='number of epochs')\n",
    "parser.add_argument('--lambda', type=float, default=10, help='weighr for cycle consistency loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('--batchSize', type=int, default=1, help='batch size')\n",
    "#     parser.add_argument('--epochs', type=int, default=200, help='number of epochs')\n",
    "#     parser.add_argument('--lr', type=float, default=0.0002, help='initial learning rate')\n",
    "#     parser.add_argument('--lambda', type=float, default=10, help='weighr for cycle consistency loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class opt():\n",
    "    batchSize = 200\n",
    "    epochs = 10\n",
    "    lr = 0.002\n",
    "    lambd = 10\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp = opt()\n",
    "hp.batchSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "batch_size = 200\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(num_epochs,acc_list,loss_list):\n",
    "    #usage : plot_graph(num_epochs,acc_list,loss_list)\n",
    "    plt.ioff()\n",
    "    fig = plt.figure()\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.ylabel('Training loss')\n",
    "    plt.plot(np.arange(num_epochs), loss_list, 'k-')\n",
    "    plt.title('Training Loss and Training Accuracy')\n",
    "    plt.xticks(np.arange(num_epochs, dtype=int))\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(np.arange(num_epochs), acc_list, 'b-')\n",
    "    plt.ylabel('Training Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.xticks(np.arange(num_epochs, dtype=int))\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"plot.png\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6287\n",
      "751\n"
     ]
    }
   ],
   "source": [
    "#256 x 256\n",
    "transform_train = [transforms.RandomCrop(256, padding=4),transforms.RandomHorizontalFlip(p=2),\n",
    "                   transforms.ToTensor(),\n",
    "                   transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])]\n",
    "transform_test = [transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])]\n",
    "trainset = ImageDataset('../datasets/monet2photo/', transforms_=transform_train,mode='train')\n",
    "testset = ImageDataset('../datasets/monet2photo/', transforms_=transform_train,mode='test')\n",
    "train_loader = DataLoader(trainset,batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(testset,batch_size=batch_size, shuffle=True)\n",
    "print(len(trainset))\n",
    "print(len(testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CycleGAN(hp).to(device)\n",
    "# scheduler = lr_scheduler.StepLR(optimizer, step_size=scheduler_step_size, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-389f56283a78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#outputs = model(images)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mlossD_A\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlossD_B\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_G\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfake_B\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcyclic_A\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfake_A\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcyclic_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;31m#loss = criterion(outputs,labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#_,preds = torch.max(outputs.data,1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/cs547/ReimplementCycleGAN/cyclegan/CycleGAN.py\u001b[0m in \u001b[0;36moptimize_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# optimize Generator: calc loss of G -> backward -> update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "loss_list = []\n",
    "for epoch in range(1,num_epochs+1):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    acc = 0.0\n",
    "    print(\"epoch {}/{}\".format(epoch,num_epochs))\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        #print(data)\n",
    "        A = data['A'].to(device)\n",
    "        B = data['B'].to(device)\n",
    "        \n",
    "        #optimizer.zero_grad()\n",
    "        #outputs = model(images)\n",
    "        model.load(A, B)\n",
    "        lossD_A,lossD_B,loss_G,fake_B,cyclic_A,fake_A,cyclic_B = model.optimize_parameters()\n",
    "        #loss = criterion(outputs,labels)\n",
    "        #_,preds = torch.max(outputs.data,1)\n",
    "        #loss.backward()\n",
    "        #optimizer.step()\n",
    "        #running_loss+=loss.item()\n",
    "        #acc+=torch.sum(preds == labels).item()\n",
    "    end_time = time.time()\n",
    "    print('Epoch:{}, Training Time: {},lossD_A :{},lossD_B:{},loss_G:{}'.format(end_time-start_time,lossD_A,lossD_B,loss_G))\n",
    "    \n",
    "#     correct = 0\n",
    "#     with torch.no_grad():\n",
    "#         #model.eval()\n",
    "#         start_time = time.time()\n",
    "#         for batch_idx, (A,B) in enumerate(test_loader):\n",
    "#             A = A.to(device)\n",
    "#             B = B.to(device)\n",
    "#             model.load(A,B)\n",
    "#             #model.optimize_parameters()\n",
    "#             #_,predicted = torch.max(outputs.data,1)\n",
    "#             #correct+=torch.sum(predicted==labels).item()\n",
    "#         end_time = time.time()\n",
    "#         print('Testing Time: ',end_time-start_time ,'s, Testing Accurarcy: ',correct/len(testset))\n",
    "    print('-' * 20)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(num_epochs,acc_list,loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model,'cycleGAN.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
