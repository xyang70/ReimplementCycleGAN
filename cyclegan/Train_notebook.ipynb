{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import datetime\n",
    "import PIL\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from CycleGAN import CycleGAN\n",
    "from ImageDataset import ImageDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--lambda'], dest='lambda', nargs=None, const=None, default=10, type=<class 'float'>, choices=None, help='weighr for cycle consistency loss', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--epoch', type=int, default=0, help='starting epoch')\n",
    "parser.add_argument('--dataroot', type=str, default='../datasets/monet2photo/', help='root directory of the dataset')\n",
    "parser.add_argument('--lr', type=float, default=0.0002, help='initial learning rate')\n",
    "parser.add_argument('--size', type=int, default=256, help='size of the data crop (squared assumed)')\n",
    "parser.add_argument('--input_nc', type=int, default=3, help='number of channels of input data')\n",
    "parser.add_argument('--output_nc', type=int, default=3, help='number of channels of output data')\n",
    "parser.add_argument('--cuda', action='store_true', help='use GPU computation')\n",
    "parser.add_argument('--n_cpu', type=int, default=8, help='number of cpu threads to use during batch generation')\n",
    "opt = parser.parse_args(args=[])\n",
    "parser.add_argument('--batchSize', type=int, default=1, help='batch size')\n",
    "parser.add_argument('--epochs', type=int, default=200, help='number of epochs')\n",
    "parser.add_argument('--lambda', type=float, default=10, help='weighr for cycle consistency loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "batch_size = 200\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(num_epochs,acc_list,loss_list):\n",
    "    #usage : plot_graph(num_epochs,acc_list,loss_list)\n",
    "    plt.ioff()\n",
    "    fig = plt.figure()\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.ylabel('Training loss')\n",
    "    plt.plot(np.arange(num_epochs), loss_list, 'k-')\n",
    "    plt.title('Training Loss and Training Accuracy')\n",
    "    plt.xticks(np.arange(num_epochs, dtype=int))\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(np.arange(num_epochs), acc_list, 'b-')\n",
    "    plt.ylabel('Training Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.xticks(np.arange(num_epochs, dtype=int))\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"plot.png\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#256 x 256\n",
    "transform_train = [transforms.RandomCrop(256, padding=4),transforms.RandomHorizontalFlip(p=2),\n",
    "                   transforms.ToTensor(),\n",
    "                   transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])]\n",
    "transform_test = [transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])]\n",
    "trainset = ImageDataset('../datasets/monet2photo/', transforms_=transform_train,mode='train')\n",
    "testset = ImageDataset('../datasets/monet2photo/', transforms_=transform_train,mode='test')\n",
    "train_loader = DataLoader(trainset,batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(testset,batch_size=batch_size, shuffle=True)\n",
    "print(len(trainset))\n",
    "print(len(testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = CycleGAN('opt').to(device)\n",
    "# scheduler = lr_scheduler.StepLR(optimizer, step_size=scheduler_step_size, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list = []\n",
    "loss_list = []\n",
    "for epoch in range(1,num_epochs+1):\n",
    "    #model.train()\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    acc = 0.0\n",
    "    print(\"epoch {}/{}\".format(epoch,num_epochs))\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        #print(data)\n",
    "        A = data['A'].to(device)\n",
    "        B = data['B'].to(device)\n",
    "        \n",
    "        #optimizer.zero_grad()\n",
    "        #outputs = model(images)\n",
    "#         model.load(img_A, imgB)\n",
    "#         model.optimize_parameters()\n",
    "        #loss = criterion(outputs,labels)\n",
    "        #_,preds = torch.max(outputs.data,1)\n",
    "        #loss.backward()\n",
    "        #optimizer.step()\n",
    "        #running_loss+=loss.item()\n",
    "        #acc+=torch.sum(preds == labels).item()\n",
    "    end_time = time.time()\n",
    "    print('Training Time: ',end_time-start_time ,'s, Training accurarcy: ',acc/len(trainset),', Training loss: ',running_loss/len(trainset))\n",
    "    \n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        #model.eval()\n",
    "        start_time = time.time()\n",
    "        for batch_idx, (A,B) in enumerate(test_loader):\n",
    "            A = A.to(device)\n",
    "            B = B.to(device)\n",
    "            #model.load(A,B)\n",
    "            #model.optimize_parameters()\n",
    "            #_,predicted = torch.max(outputs.data,1)\n",
    "            #correct+=torch.sum(predicted==labels).item()\n",
    "        end_time = time.time()\n",
    "        print('Testing Time: ',end_time-start_time ,'s, Testing Accurarcy: ',correct/len(testset))\n",
    "    print('-' * 20)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(num_epochs,acc_list,loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model,'cycleGAN.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
